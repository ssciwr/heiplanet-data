{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Personal Notebook for exploring nc files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Note on aggregation method\n",
    "\n",
    "* `mean`\n",
    "    * with `geopandas`: simply calculating mean on all grid cells in a NUTS region. There is no weighted area.\n",
    "    * with `exactaxtract`: [reference](https://github.com/isciences/exactextract/blob/master/python/doc/operations.rst)\n",
    "        * `mean`: Mean value of cells that intersect the polygon, weighted by the percent of each cell that is covered. Usually used for average temperature.\n",
    "        * `weighted_mean`: Mean value of cells that intersect the polygon, weighted by the product over the coverage fraction and the weighting raster. Usually used for population-weighted average temperature\n",
    "    * only calculate mean on non-nan values. **If all values are `nan`, then return `nan`**\n",
    "* `sum`\n",
    "    * with `geopandas`: simply calculating sum on all grid cells in a NUTS region. There is no weighted area.\n",
    "    * with `exactextract`: Sum of values of raster cells that intersect the polygon, with each raster value weighted by its coverage fraction. Usually used for total population\n",
    "    * only calculate mean on non-nan values. **If all values are `nan`, then return `0.0`**. This is mathematically makes sense for population value. But how about other total data variables, such as total precipitation,  radiation, soil moisture, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import xagg as xa\n",
    "import exactextract as ee\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../docs/source/notebooks/processed/era5_data_2016-2017_allm_2t_tp_monthly_unicoords_adjlon_celsius_mm_tutorial_B.nc\"  # 0.1 deg\n",
    "nuts_file = \"../data/in/NUTS_RG_20M_2024_4326.shp.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRS = \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(data_file, chunks={\"time\": \"auto\"}) as ds:\n",
    "    df = ds.to_dataframe().reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[[\"latitude\", \"longitude\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is row where t2m or tp is NaN but not both\n",
    "df_nan = df[\n",
    "    (df[\"t2m\"].isna() & ~df[\"tp\"].isna()) | (~df[\"t2m\"].isna() & df[\"tp\"].isna())\n",
    "]\n",
    "len(df_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts = gpd.read_file(nuts_file)\n",
    "len(nuts.NUTS_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Using purely geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "**Note: Can't run for now with 0.1 deg as the data is too large (causing crashed kernel or VSCode)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "When using purely `geopandas.sjoin`, there are 448 NUTS_IDs that do not have points intersecting with their areas, and 422 NUTS_IDs that have `NaN` for `t2m` or `tp` due to the original dataset. However, after groupping by NUTS_ID and time, 422 `NaN` cases are reduced to 123 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert xarray dataset to pandas dataframe\n",
    "gpd_ds = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df[\"longitude\"], df[\"latitude\"]),\n",
    "    crs=CRS,\n",
    ")\n",
    "gpd_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with nuts geodataframe\n",
    "merged = gpd.sjoin(gpd_ds, nuts, how=\"inner\", predicate=\"within\")\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd_groupped = merged.groupby([\"NUTS_ID\", \"time\"], as_index=False).agg(\n",
    "    {\"t2m\": \"mean\", \"tp\": \"mean\"}\n",
    ")\n",
    "gpd_groupped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gpd_groupped)  # 32400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count NUTS_IDs that have nan t2m or tp\n",
    "gdp_nan_t2m = merged[merged[\"t2m\"].isna()][\"NUTS_ID\"].unique()\n",
    "gdp_nan_tp = merged[merged[\"tp\"].isna()][\"NUTS_ID\"].unique()\n",
    "\n",
    "(\n",
    "    len(gdp_nan_t2m),\n",
    "    len(gdp_nan_tp),\n",
    "    set(gdp_nan_t2m) - set(gdp_nan_tp),\n",
    "    set(gdp_nan_tp) - set(gdp_nan_t2m),\n",
    ")  # 422, 422, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gpd_groupped[gpd_groupped[\"t2m\"].isna()][\"NUTS_ID\"].unique())  # 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test mean of nan of geopandas\n",
    "# create a small test geodataframe\n",
    "test_gdf = gpd.GeoDataFrame(\n",
    "    {\n",
    "        \"NUTS_ID\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"],\n",
    "        \"t2m\": [1.0, 2.0, None, None, None, None],\n",
    "    }\n",
    ")\n",
    "test_gdf_grouped_mean = test_gdf.groupby(\"NUTS_ID\", as_index=False).agg({\"t2m\": \"mean\"})\n",
    "test_gdf_grouped_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gdf_grouped_sum = test_gdf.groupby(\"NUTS_ID\", as_index=False).agg({\"t2m\": \"sum\"})\n",
    "test_gdf_grouped_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged.NUTS_ID), len(merged.NUTS_ID.unique()), len(merged.geometry.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get specific values of merged for checking\n",
    "merged_sample = merged[\n",
    "    np.isclose(merged[\"latitude\"], 89.75, atol=1e-6)\n",
    "    & (merged[\"time\"] == \"2016-01-15 12:00:00\")\n",
    "]\n",
    "merged_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any geometries that map to multiple NUTS_IDs\n",
    "# and among these NUTS_IDs, there is no hierarchy relationship\n",
    "from collections import defaultdict\n",
    "\n",
    "geom_to_nuts = defaultdict(list)\n",
    "for geom, nuts_id in zip(merged.geometry, merged.NUTS_ID):\n",
    "    geom_to_nuts[geom].append(nuts_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_geoms = {\n",
    "    geom: nuts_ids for geom, nuts_ids in geom_to_nuts.items() if len(nuts_ids) > 1\n",
    "}\n",
    "len(repeated_geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_geoms = defaultdict(list)\n",
    "for geom, nuts_ids in repeated_geoms.items():\n",
    "    common_prefix = os.path.commonprefix(nuts_ids)\n",
    "    if not common_prefix:\n",
    "        shared_geoms[geom] = nuts_ids\n",
    "len(shared_geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any NUTS_IDS that do not map to any geometry\n",
    "all_nuts_ids = set(nuts.NUTS_ID.unique())\n",
    "mapped_nuts_ids = set(merged.NUTS_ID.unique())\n",
    "unmapped_nuts_ids = all_nuts_ids - mapped_nuts_ids\n",
    "len(unmapped_nuts_ids)  # 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(unmapped_nuts_ids)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check if NUTS_ID is indeed not in merged\n",
    "merged[merged[\"NUTS_ID\"] == \"NL226\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect geometries that do not map to any data point\n",
    "unmapped_nuts = nuts[nuts[\"NUTS_ID\"] == \"NL226\"]\n",
    "unmapped_nuts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check range of lat lon in this unmapped nuts region\n",
    "unmapped_nuts.total_bounds  # minx, miny, maxx, maxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter closed ranges of lat lon from gpd_ds\n",
    "minx, miny, maxx, maxy = unmapped_nuts.total_bounds\n",
    "gpd_ds_filtered = gpd_ds[\n",
    "    (gpd_ds[\"longitude\"] >= minx)\n",
    "    & (gpd_ds[\"longitude\"] <= maxx)\n",
    "    & (gpd_ds[\"latitude\"] >= miny)\n",
    "    & (gpd_ds[\"latitude\"] <= maxy)\n",
    "]\n",
    "len(gpd_ds_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_points = gpd_ds_filtered[\"geometry\"].unique()\n",
    "filtered_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if filtered points is within the unmapped_nuts geometry\n",
    "within_flags = [unmapped_nuts.contains(point).any() for point in filtered_points]\n",
    "within_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any geometries that do not map to any NUTS_ID\n",
    "all_geoms = set(gpd_ds.geometry.unique())\n",
    "mapped_geoms = set(merged.geometry.unique())\n",
    "unmapped_geoms = all_geoms - mapped_geoms\n",
    "unmapped_geoms = list(unmapped_geoms)\n",
    "len(unmapped_geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmapped_geoms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are NUTS3 inside another NUTS3\n",
    "nuts3 = nuts[nuts.LEVL_CODE == 3]\n",
    "nuts3_sjoined = gpd.sjoin(nuts3, nuts3, how=\"inner\", predicate=\"within\")\n",
    "nuts3_sjoined_diff = nuts3_sjoined[\n",
    "    nuts3_sjoined.NUTS_ID_left != nuts3_sjoined.NUTS_ID_right\n",
    "]\n",
    "(\n",
    "    len(nuts3),\n",
    "    len(nuts3_sjoined),\n",
    "    len(nuts3_sjoined_diff),\n",
    "    len(set(nuts3_sjoined.NUTS_ID_left)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if NUTS3 touch other NUTS3\n",
    "nuts3_sjoined_other = gpd.sjoin(nuts3, nuts3, how=\"inner\", predicate=\"touches\")\n",
    "nuts3_sjoined_other_diff = nuts3_sjoined_other[\n",
    "    nuts3_sjoined_other.NUTS_ID_left != nuts3_sjoined_other.NUTS_ID_right\n",
    "]\n",
    "(\n",
    "    len(nuts3_sjoined_other),\n",
    "    len(nuts3_sjoined_other_diff),\n",
    "    len(set(nuts3_sjoined_other_diff.NUTS_ID_left)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is NUTS inside another NUTS\n",
    "nuts_sjoined = gpd.sjoin(nuts, nuts, how=\"inner\", predicate=\"within\")\n",
    "# get all rows where NUTS_IDs are different and don't share common prefix\n",
    "nuts_sjoined_diff = nuts_sjoined[\n",
    "    nuts_sjoined.NUTS_ID_left != nuts_sjoined.NUTS_ID_right\n",
    "]\n",
    "shared_nuts = []\n",
    "for _, row in nuts_sjoined_diff.iterrows():\n",
    "    common_prefix = os.path.commonprefix([row.NUTS_ID_left, row.NUTS_ID_right])\n",
    "    if not common_prefix:\n",
    "        shared_nuts.append(row)\n",
    "len(shared_nuts), len(nuts_sjoined), len(nuts_sjoined_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts[nuts.CNTR_CODE == \"BA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts[nuts.NUTS_ID == \"DE502\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts[(nuts.CNTR_CODE == \"DE\") & (nuts.LEVL_CODE == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all nuts related to Bremen\n",
    "bremen_nuts_ids = nuts[nuts.NUTS_NAME == \"Bremen\"][[\"NUTS_ID\"]].NUTS_ID.tolist()\n",
    "bremen_root = sorted(bremen_nuts_ids, key=len)[0]\n",
    "bremen_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all nuts under DE5\n",
    "bremen_nuts = nuts[nuts.NUTS_ID.str.startswith(\"DE5\")]\n",
    "bremen_nuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if DE50 actually within DE5\n",
    "de5_geom = nuts[nuts.NUTS_ID == \"DE5\"].geometry\n",
    "de50_geom = nuts[nuts.NUTS_ID == \"DE50\"].geometry\n",
    "de50_geom.within(de5_geom.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "de501_geom = nuts[nuts.NUTS_ID == \"DE501\"].geometry\n",
    "de502_geom = nuts[nuts.NUTS_ID == \"DE502\"].geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "de501_geom.within(de5_geom.iloc[0]), de502_geom.within(de5_geom.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "de501_geom.within(de50_geom.iloc[0]), de502_geom.within(de50_geom.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any NUTSi that is not within its parent NUTS(i-1)\n",
    "not_within_cases = []\n",
    "ctrn_codes = nuts.CNTR_CODE.unique()\n",
    "for ctrn_code in ctrn_codes:\n",
    "    nuts_subset = nuts[nuts.NUTS_ID.str.startswith(ctrn_code)][\n",
    "        [\"NUTS_ID\"]\n",
    "    ].NUTS_ID.tolist()\n",
    "    nuts_subset.sort(key=len)  # parent NUTS will appear before child NUTS\n",
    "    for nuts_id in nuts_subset:\n",
    "        parent_id = nuts_id[:-1] if len(nuts_id) > len(ctrn_code) else None\n",
    "        if parent_id is None:\n",
    "            continue\n",
    "        check_within = gpd.sjoin(\n",
    "            nuts[nuts.NUTS_ID == nuts_id],\n",
    "            nuts[nuts.NUTS_ID == parent_id],\n",
    "            how=\"inner\",\n",
    "            predicate=\"within\",\n",
    "        )\n",
    "        if len(check_within) == 0:\n",
    "            not_within_cases.append((nuts_id, parent_id))\n",
    "len(not_within_cases), not_within_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## Aggregate data by NUTS using xagg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "**Note: Can't run for now with 0.1 deg as the data is too large (took more than 20 minutes for aggregating t2m only)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "When using `xagg` for aggregation, there are in total 114 NUTS_IDs with `NaN` `t2m` or `tp`:\n",
    "* 57 cases are due to the original values of `t2m` and `tp` in the original dataset\n",
    "* 57 cases because the areas are too small\n",
    "\n",
    "However, it seems like we can only calculate average (mean) with `xagg`. There is no other options for aggregation like `sum`, `min`, or `max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cartopy matplotlib cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are nans in t2m or tp before aggregation\n",
    "nan_t2m_ds = df[df[\"t2m\"].isna()]\n",
    "nan_tp_ds = df[df[\"tp\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nan_t2m_ds[[\"latitude\", \"longitude\"]].drop_duplicates()), len(nan_tp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get overlap between pixels and polygons\n",
    "weightmap = xa.pixel_overlaps(ds, nuts)\n",
    "weightmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get row 50 of the nuts\n",
    "nuts.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightmap.diag_fig({\"NUTS_ID\": \"BA01\"}, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate dat in ds onto polygons in nuts\n",
    "agg_ds = xa.aggregate(ds, weightmap)\n",
    "agg_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ds = agg_ds.to_dataset()\n",
    "out_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = out_ds.to_dataframe().reset_index()\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many got mapped\n",
    "len(out_df), len(out_df.NUTS_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any NUTS ID that does not have t2m or tp mapped\n",
    "nan_t2m = out_df[out_df[\"t2m\"].isna()][\"NUTS_ID\"].unique()\n",
    "nan_tp = out_df[out_df[\"tp\"].isna()][\"NUTS_ID\"].unique()\n",
    "(\n",
    "    len(nan_t2m),\n",
    "    len(nan_tp),\n",
    "    set(nan_t2m) - set(nan_tp),\n",
    "    set(nan_tp) - set(nan_t2m),\n",
    ")  # 114, 114, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find common IDs with unmapped_nuts_ids from geopandas sjoin\n",
    "common_ids = set(nan_t2m).intersection(set(unmapped_nuts_ids))\n",
    "len(common_ids)  # 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if NUTS_ID in nan_t2m is because t2m is nan in the original dataset\n",
    "nan_t2m_from_org = []\n",
    "nan_t2m_not_from_org = []\n",
    "nan_t2m_points = gpd_ds[gpd_ds[\"t2m\"].isna()][\"geometry\"].unique()\n",
    "for nuts_id in nan_t2m:\n",
    "    nuts_geom = nuts[nuts[\"NUTS_ID\"] == nuts_id]\n",
    "    check_contains = gpd.sjoin(\n",
    "        gpd.GeoDataFrame(geometry=nan_t2m_points, crs=CRS),\n",
    "        nuts_geom,\n",
    "        how=\"inner\",\n",
    "        predicate=\"within\",\n",
    "    )\n",
    "    if len(check_contains) > 0:\n",
    "        nan_t2m_from_org.append(nuts_id)  # because of nan in original data\n",
    "    else:\n",
    "        nan_t2m_not_from_org.append(nuts_id)  # not because of nan in original data\n",
    "\n",
    "len(nan_t2m_from_org), len(nan_t2m_not_from_org)  # 57, 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_t2m_not_from_org[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if these two lists have common ids with the ones from geopandas sjoin\n",
    "common_ids_org = set(nan_t2m_from_org).intersection(set(unmapped_nuts_ids))\n",
    "common_ids_not_org = set(nan_t2m_not_from_org).intersection(set(unmapped_nuts_ids))\n",
    "len(common_ids_org), len(common_ids_not_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common ids with gdp_nan_t2m of geopandas sjoin\n",
    "common_ids_gdp = set(nan_t2m).intersection(set(gdp_nan_t2m))\n",
    "common_ids_gdp_org = set(nan_t2m_from_org).intersection(set(gdp_nan_t2m))\n",
    "common_ids_gdp_not_org = set(nan_t2m_not_from_org).intersection(set(gdp_nan_t2m))\n",
    "len(common_ids_gdp), len(common_ids_gdp_org), len(common_ids_gdp_not_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the unmapped NUTS_ID with geopandas is also unmapped here\n",
    "out_df[out_df[\"NUTS_ID\"] == \"BE233\"][[\"NUTS_ID\", \"t2m\", \"tp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one of the unmapped NUTS_ID region\n",
    "unmapped_nuts_id = \"BE233\"\n",
    "unmapped_nuts_region = nuts[nuts[\"NUTS_ID\"] == unmapped_nuts_id]\n",
    "unmapped_nuts_region.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check lat lon range of this unmapped NUTS region\n",
    "unmapped_nuts_region.total_bounds  # minx, miny, maxx, maxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find if there is any grid point within this unmapped NUTS region\n",
    "minx, miny, maxx, maxy = unmapped_nuts_region.total_bounds\n",
    "gpd_ds_filtered = gpd_ds[\n",
    "    (gpd_ds[\"longitude\"] >= minx)\n",
    "    & (gpd_ds[\"longitude\"] <= maxx)\n",
    "    & (gpd_ds[\"latitude\"] >= miny)\n",
    "    & (gpd_ds[\"latitude\"] <= maxy)\n",
    "]\n",
    "len(gpd_ds_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_points = gpd_ds_filtered[\"geometry\"].unique()\n",
    "filtered_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if filtered points is within the unmapped_nuts geometry\n",
    "within_flags = [unmapped_nuts.contains(point).any() for point in filtered_points]\n",
    "within_flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "## Aggregate data by NUTS using exactextract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "Using `exactextract` yields the same results as with `xagg`, when calculating `mean` for all data variables.\n",
    "\n",
    "We can specify aggregation method for each data variable with `exactextract`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems like rioxarray is installed but used by exactextract\n",
    "import rioxarray as rxr  # noqa: F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell seems unnecessary\n",
    "# # ensure CRS is defined\n",
    "# ds = ds.rio.write_crs(CRS, inplace=True)\n",
    "\n",
    "# # tell rioxarray which dimensions are x and y\n",
    "# ds = ds.rio.set_spatial_dims(x_dim=\"longitude\", y_dim=\"latitude\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate t2m and tp for exactextract\n",
    "ds_t2m = ds[[\"t2m\"]]\n",
    "ds_tp = ds[[\"tp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate for each time step separately\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "for t in ds.time.values:\n",
    "    t2m_t = ds_t2m.sel(time=t)\n",
    "    tp_t = ds_tp.sel(time=t)\n",
    "\n",
    "    t2m_stats = ee.exact_extract(\n",
    "        t2m_t, nuts, \"t2m_mean=mean\", include_cols=[\"NUTS_ID\"], output=\"pandas\"\n",
    "    )\n",
    "    t2m_stats[\"time\"] = t\n",
    "    results.append(t2m_stats)\n",
    "\n",
    "    tp_stats = ee.exact_extract(\n",
    "        tp_t,\n",
    "        nuts,\n",
    "        \"tp_mean=mean\",  # note that if sum is used, sum of all NaN will be 0\n",
    "        include_cols=[\"NUTS_ID\"],\n",
    "        output=\"pandas\",\n",
    "    )\n",
    "    tp_stats[\"time\"] = t\n",
    "    results.append(tp_stats)\n",
    "    print(\n",
    "        \"Done for time\", t\n",
    "    )  # in total, ~ 5 minutes for 0.5 deg, ~ 8 minutes for 0.1 deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfs = [\n",
    "    pd.merge(\n",
    "        results[i],\n",
    "        results[i + 1],\n",
    "        on=[\"NUTS_ID\", \"time\"],\n",
    "        how=\"outer\",\n",
    "        validate=\"1:1\",\n",
    "    )\n",
    "    for i in range(0, len(results), 2)\n",
    "]\n",
    "agg_df = pd.concat(merged_dfs, ignore_index=True)\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results[0]), len(results[1]), len(agg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(results[0][\"NUTS_ID\"].unique()) - set(agg_df[\"NUTS_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg_df[\"NUTS_ID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUTS_IDs with NaN t2m or tp\n",
    "nan_t2m_ids = agg_df[agg_df[\"t2m_mean\"].isna()][\"NUTS_ID\"].unique()\n",
    "nan_tp_ids = agg_df[agg_df[\"tp_mean\"].isna()][\"NUTS_ID\"].unique()\n",
    "(\n",
    "    len(nan_t2m_ids),\n",
    "    len(nan_tp_ids),\n",
    "    len(set(nan_t2m_ids) - set(nan_tp_ids)),\n",
    "    len(set(nan_tp_ids) - set(nan_t2m_ids)),\n",
    ")  # 114, 114, 0, 0 for 0.5 deg; 1, 1, 0, 0 for 0.1 deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tp_mean from NUTS_IDs with NaN t2m\n",
    "nan_t2m_not_nan_tp = agg_df[agg_df[\"NUTS_ID\"].isin(nan_t2m_ids)][\"tp_mean\"].unique()\n",
    "nan_t2m_not_nan_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_t2m_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if NUTS_ID in nan_t2m _ids is because t2m is nan in the original dataset\n",
    "ee_nan_t2m_from_org = []\n",
    "ee_nan_t2m_not_from_org = []\n",
    "nan_t2m_points = df[df[\"t2m\"].isna()][[\"latitude\", \"longitude\"]].drop_duplicates()\n",
    "for nuts_id in nan_t2m_ids:\n",
    "    nuts_geom = nuts[nuts[\"NUTS_ID\"] == nuts_id]\n",
    "    check_contains = gpd.sjoin(\n",
    "        gpd.GeoDataFrame(\n",
    "            geometry=gpd.points_from_xy(\n",
    "                x=nan_t2m_points[\"longitude\"], y=nan_t2m_points[\"latitude\"]\n",
    "            ),\n",
    "            crs=CRS,\n",
    "        ),\n",
    "        nuts_geom,\n",
    "        how=\"inner\",\n",
    "        predicate=\"within\",\n",
    "    )\n",
    "    if len(check_contains) > 0:\n",
    "        ee_nan_t2m_from_org.append(nuts_id)  # because of nan in original data\n",
    "    else:\n",
    "        ee_nan_t2m_not_from_org.append(nuts_id)  # not because of nan in original data\n",
    "\n",
    "(\n",
    "    len(ee_nan_t2m_from_org),\n",
    "    len(ee_nan_t2m_not_from_org),\n",
    ")  # 57, 57 for 0.5 deg; 0, 1 for 0.1 deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot one of the unmapped NUTS_ID region\n",
    "unmapped_nuts_id = \"MT002\"\n",
    "unmapped_nuts_region = nuts[nuts[\"NUTS_ID\"] == unmapped_nuts_id]\n",
    "unmapped_nuts_region.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check lat lon range of this unmapped NUTS region\n",
    "unmapped_nuts_region.total_bounds  # minx, miny, maxx, maxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find if there is any grid point within this unmapped NUTS region\n",
    "minx, miny, maxx, maxy = unmapped_nuts_region.total_bounds\n",
    "df_filtered = df[\n",
    "    (df[\"longitude\"] >= minx)\n",
    "    & (df[\"longitude\"] <= maxx)\n",
    "    & (df[\"latitude\"] >= miny)\n",
    "    & (df[\"latitude\"] <= maxy)\n",
    "]\n",
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "## Compare between 3 methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare between geopandas sjoin, xagg, and exactextract results\n",
    "nuts_id = \"DE\"\n",
    "time = \"2016-01-01\"\n",
    "gpd_result = gpd_groupped[\n",
    "    (gpd_groupped[\"NUTS_ID\"] == nuts_id) & (gpd_groupped[\"time\"] == time)\n",
    "][[\"NUTS_ID\", \"time\", \"t2m\", \"tp\"]]\n",
    "xagg_result = out_df[(out_df[\"NUTS_ID\"] == nuts_id) & (out_df[\"time\"] == time)][\n",
    "    [\"NUTS_ID\", \"time\", \"t2m\", \"tp\"]\n",
    "]\n",
    "exactextract_result = agg_df[(agg_df[\"NUTS_ID\"] == nuts_id) & (agg_df[\"time\"] == time)][\n",
    "    [\"NUTS_ID\", \"time\", \"t2m_mean\", \"tp_mean\"]\n",
    "]\n",
    "gpd_result, xagg_result, exactextract_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if these two lists have common ids with the ones from geopandas sjoin\n",
    "ee_common_ids_org = set(ee_nan_t2m_from_org).intersection(set(unmapped_nuts_ids))\n",
    "ee_common_ids_not_org = set(ee_nan_t2m_not_from_org).intersection(\n",
    "    set(unmapped_nuts_ids)\n",
    ")\n",
    "len(ee_common_ids_org), len(ee_common_ids_not_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common ids with gdp_nan_t2m of geopandas sjoin\n",
    "ee_common_ids_gdp = set(nan_t2m_ids).intersection(set(gdp_nan_t2m))\n",
    "ee_common_ids_gdp_org = set(ee_nan_t2m_from_org).intersection(set(gdp_nan_t2m))\n",
    "ee_common_ids_gdp_not_org = set(ee_nan_t2m_not_from_org).intersection(set(gdp_nan_t2m))\n",
    "len(ee_common_ids_gdp), len(ee_common_ids_gdp_org), len(ee_common_ids_gdp_not_org)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onehealthdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
